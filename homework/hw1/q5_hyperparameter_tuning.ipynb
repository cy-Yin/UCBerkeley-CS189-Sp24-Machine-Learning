{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy of q3b: Evaluation metric\n",
    "\n",
    "def eval_metric(true_labels, predicted_labels):\n",
    "    \"\"\"\n",
    "    use classification accuracy, or the percent of examples classified correctly,\n",
    "    as a measure of the classifier performance.\n",
    "    \n",
    "    Args:\n",
    "        true_labels: the set of true labels of the dataset\n",
    "        predicted_labels: the set of labels predicted by the model\n",
    "    \n",
    "    Returns:\n",
    "        the (unweighted) accuracy score\n",
    "    \"\"\"\n",
    "    assert len(true_labels) == len(predicted_labels)\n",
    "    total_num = len(true_labels)\n",
    "    accurate_num = 0\n",
    "    for i in range(total_num):\n",
    "        if true_labels[i] == predicted_labels[i]:\n",
    "            accurate_num += 1\n",
    "    \n",
    "    return accurate_num / total_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a linear SVM on the MNIST dataset with a given hyperparameter C\n",
    "\n",
    "def mnist_linear_svm(train_data_subset, train_labels_subset, hyper_c):\n",
    "    # use linear SVM to train the model\n",
    "    model = svm.SVC(kernel=\"linear\", max_iter=10000, C=hyper_c)\n",
    "    model.fit(train_data_subset, train_labels_subset)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data = np.load(\"data/mnist-data.npz\")\n",
    "fields = \"test_data\", \"training_data\", \"training_labels\"\n",
    "mnist_train_val_data = mnist_data[fields[1]]\n",
    "mnist_train_val_labels = mnist_data[fields[2]]\n",
    "# For the MNIST dataset, write code that sets aside 10,000 training images as a validation set.\n",
    "mnist_val_data_num = 10000\n",
    "train_set_size = 12000 # use 12,000 samples as train subset\n",
    "mnist_indices = np.random.permutation(len(mnist_train_val_data))\n",
    "mnist_val_data = mnist_train_val_data[mnist_indices[:mnist_val_data_num]]\n",
    "mnist_val_labels = mnist_train_val_labels[mnist_indices[:mnist_val_data_num]]\n",
    "mnist_train_data = mnist_train_val_data[mnist_indices[mnist_val_data_num:]]\n",
    "mnist_train_labels = mnist_train_val_labels[mnist_indices[mnist_val_data_num:]]\n",
    "# train the model with 0~train_set_size subset of all the train data\n",
    "mnist_train_data_subset = mnist_train_data[:train_set_size]\n",
    "mnist_train_labels_subset = mnist_train_labels[:train_set_size]\n",
    "\n",
    "# In MNIST, our feature vector for an image will be a row vector with all the pixel values\n",
    "# concatenated in a row major (or column major) order\n",
    "flattened_mnist_train_data_subset = mnist_train_data_subset.reshape((train_set_size, -1))\n",
    "flattened_mnist_val_data = mnist_val_data.reshape((mnist_val_data_num, -1))\n",
    "\n",
    "mnist_hyper_C = np.array((1.e-10, 1.e-9, 1.e-8, 1.e-7, 1.e-6, 1.e-5, 1.e-4, 1.e-3, 1.e-2, 1.e-1, 1, 10))\n",
    "mnist_training_accuracies = np.zeros(len(mnist_hyper_C))\n",
    "mnist_validation_accuracies = np.zeros(len(mnist_hyper_C))\n",
    "mnist_index = 0\n",
    "for hyper_c in mnist_hyper_C:\n",
    "    model = mnist_linear_svm(flattened_mnist_train_data_subset, mnist_train_labels_subset, hyper_c)\n",
    "    pred_mnist_val_labels = model.predict(flattened_mnist_val_data)\n",
    "    pred_mnist_train_labels_subset = model.predict(flattened_mnist_train_data_subset)\n",
    "    mnist_training_accuracies[mnist_index] = \\\n",
    "        eval_metric(mnist_train_labels_subset, pred_mnist_train_labels_subset)\n",
    "    mnist_validation_accuracies[mnist_index] = \\\n",
    "        eval_metric(mnist_val_labels, pred_mnist_val_labels)\n",
    "    mnist_index += 1\n",
    "\n",
    "# Plot the accuracies\n",
    "plt.plot(mnist_hyper_C, mnist_training_accuracies, label=\"MNIST training accuracy\") \n",
    "plt.plot(mnist_hyper_C, mnist_validation_accuracies, label=\"MNIST validation accuracy\")\n",
    "plt.title(\"MNIST-linearSVM Accuracy vs Hyperparameter C\")\n",
    "plt.xlabel(\"hyper-C\")\n",
    "plt.xscale(\"log\")\n",
    "plt.ylabel(\"training and validation accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(\"q5_hyper_tuning.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
