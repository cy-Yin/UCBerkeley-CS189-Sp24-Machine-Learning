{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy of q3b: Evaluation metric\n",
    "\n",
    "def eval_metric(true_labels, predicted_labels):\n",
    "    \"\"\"\n",
    "    use classification accuracy, or the percent of examples classified correctly,\n",
    "    as a measure of the classifier performance.\n",
    "    \n",
    "    Args:\n",
    "        true_labels: the set of true labels of the dataset\n",
    "        predicted_labels: the set of labels predicted by the model\n",
    "    \n",
    "    Returns:\n",
    "        the (unweighted) accuracy score\n",
    "    \"\"\"\n",
    "    assert len(true_labels) == len(predicted_labels)\n",
    "    total_num = len(true_labels)\n",
    "    accurate_num = 0\n",
    "    for i in range(total_num):\n",
    "        if true_labels[i] == predicted_labels[i]:\n",
    "            accurate_num += 1\n",
    "    \n",
    "    return accurate_num / total_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a linear SVM on the MNIST dataset with a given hyperparameter C\n",
    "\n",
    "def spam_linear_svm(train_data, train_labels, hyper_c):\n",
    "    # use linear SVM to train the model\n",
    "    model = svm.SVC(kernel=\"linear\", C=hyper_c)\n",
    "    model.fit(train_data, train_labels)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_k_fold_split(data, labels, k):\n",
    "    \"\"\"\n",
    "    randomly split the dataset into k-folds\n",
    "    \n",
    "    Args:\n",
    "        data: the to-be-split dataset\n",
    "        labels: the labels of the to-be-split dataset\n",
    "        k: the wanted k-fold\n",
    "    \n",
    "    Returns:\n",
    "        data_folds: an array contain k elements, each of which is a split set containing data\n",
    "        labels_folds: an array contain k elements, each of which is a split set containing labels\n",
    "    \"\"\"\n",
    "    assert len(data) == len(labels)\n",
    "    n_samples = len(data)\n",
    "    indices = np.random.permutation(n_samples)\n",
    "    \n",
    "    # generate k-1 points from 1 to n_samples - 1,\n",
    "    # so the dataset can be split into k-fold by these k-1 points\n",
    "    cut_points = np.sort(np.random.choice(range(1, n_samples), k - 1, replace=False))\n",
    "    \n",
    "    data_folds = []\n",
    "    labels_folds = []\n",
    "    prev = 0\n",
    "    for cut_point in cut_points:\n",
    "        data_folds.append(data[indices[prev:cut_point]])\n",
    "        labels_folds.append(labels[indices[prev:cut_point]])\n",
    "        prev = cut_point\n",
    "    # cope with the final k-th set\n",
    "    data_folds.append(data[indices[prev:]])\n",
    "    labels_folds.append(labels[indices[prev:]])\n",
    "    \n",
    "    return data_folds, labels_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kFold_cross_validation(train_val_data, train_val_labels, k, hyper_c):\n",
    "    data_folds, labels_folds = random_k_fold_split(train_val_data, train_val_labels, k)\n",
    "    train_acc_sum = 0\n",
    "    val_acc_sum = 0\n",
    "    for i in range(k):\n",
    "        # the i-th fold is the validation set\n",
    "        # other (k - 1) folds are used as the training set\n",
    "        val_data = data_folds[i]\n",
    "        filtered_data_folds = [arr for idx, arr in enumerate(data_folds) if idx != i]\n",
    "        train_data = np.concatenate(filtered_data_folds, axis=0)\n",
    "        val_labels = labels_folds[i]\n",
    "        filtered_labels_folds = [arr for idx, arr in enumerate(labels_folds) if idx != i]\n",
    "        train_labels = np.concatenate(filtered_labels_folds, axis=0)\n",
    "        \n",
    "        model = spam_linear_svm(train_data, train_labels, hyper_c)\n",
    "        pred_train_labels = model.predict(train_data)\n",
    "        pred_val_labels = model.predict(val_data)\n",
    "        train_acc_sum += eval_metric(train_labels, pred_train_labels)\n",
    "        val_acc_sum += eval_metric(val_labels, pred_val_labels)\n",
    "\n",
    "    train_acc = train_acc_sum / k\n",
    "    val_acc = val_acc_sum / k\n",
    "\n",
    "    return train_acc, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the spam dataset\n",
    "spam_data = np.load(\"data/spam-data.npz\")\n",
    "fields = \"test_data\", \"training_data\", \"training_labels\"\n",
    "spam_train_val_data = spam_data[fields[1]]\n",
    "spam_train_val_labels = spam_data[fields[2]]\n",
    "\n",
    "spam_hyper_C = np.array((1.e-9, 1.e-8, 1.e-7, 1.e-6, 1.e-5, 1.e-4, 1.e-3, 1.e-2, 1.e-1, 1, 10))\n",
    "spam_training_accuracies = np.zeros(len(spam_hyper_C))\n",
    "spam_validation_accuracies = np.zeros(len(spam_hyper_C))\n",
    "\n",
    "k = 5\n",
    "spam_index = 0\n",
    "for hyper_c in spam_hyper_C:\n",
    "    spam_training_accuracies[spam_index], spam_validation_accuracies[spam_index] = \\\n",
    "        kFold_cross_validation(spam_train_val_data, spam_train_val_labels, k, hyper_c)\n",
    "    spam_index += 1\n",
    "\n",
    "# Plot the accuracies\n",
    "plt.plot(spam_hyper_C, spam_training_accuracies, label=\"spam training accuracy\") \n",
    "plt.plot(spam_hyper_C, spam_validation_accuracies, label=\"spam validation accuracy\")\n",
    "plt.title(\"spam-kFold-Cross-Validation Accuracy vs Hyperparameter C\")\n",
    "plt.xlabel(\"hyper-C\")\n",
    "plt.xscale(\"log\")\n",
    "plt.ylabel(\"training and validation accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(\"q6_k-fold_cross-validation.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
